const __vite__mapDeps=(i,m=__vite__mapDeps,d=(m.f||(m.f=["assets/carousel-h0EPuWW_.css","assets/index-D5BC0Hiv.js","assets/index-Ksu4doOX.js","assets/index-Bj7Nea_q.css","assets/index-Chjiymov.js","assets/react-katex-447OEPN7.js"])))=>i.map(i=>d[i]);
import{u as p,r as s,_ as r,j as e}from"./index-Ksu4doOX.js";const u=s.lazy(async()=>(await r(()=>Promise.resolve({}),__vite__mapDeps([0])),{default:(await r(()=>import("./index-D5BC0Hiv.js").then(t=>t.i),__vite__mapDeps([1,2,3,4]))).Carousel})),g={mutagenesis:{title:"Mutagenesis",media:[{type:"video",src:"/portfolio/mutagenesis.webm"},{type:"image",src:"/portfolio/mutagenesis2.webp"},{type:"image",src:"/portfolio/mutagenesis3.webp"},{type:"image",src:"/portfolio/mutagenesis4.webp"}],duration:"6 months",engine:"Unity (C#)",introduction:e.jsxs(e.Fragment,{children:[e.jsxs("p",{children:["Mutagenesis is a ",e.jsx("strong",{children:"2D top-down shooter"})," I developed in Unity for my final year university project, designed to explore how AI can dynamically adapt a game’s difficulty to enhance the player experience. I built the entire system, from procedural generation and enemy AI to the underlying ",e.jsx("strong",{children:"dynamic difficulty adjustment (DDA)"})," system, to explore how gameplay can evolve in real-time in response to player behaviour."]}),e.jsxs("p",{children:["The DDA framework is achieved through a ",e.jsx("strong",{children:"dual-layer approach"}),": an adaptive loot system to ensure fair but unpredictable resource distribution, and a genetic algorithm to evolve enemy parameters in response to player behaviour. These systems work in tandem to maintain fairness without relying on static difficulty modes."]}),e.jsxs("p",{children:["This project was an opportunity to push my technical and design skills further than ever before. I developed multiple advanced systems that required careful architectural planning and efficient communication between them, achieving a level of sophistication I hadn’t previously attempted when developing games. Building these interconnected systems presented a significant challenge, demanding a ",e.jsx("strong",{children:"strong emphasis on modularity, performance, and clean, maintainable code"}),". Mutagenesis ultimately represents the culmination of my technical growth in Unity and my applied understanding of artificial intelligence at the time."]})]}),body:({InlineMath:a,BlockMath:t})=>e.jsxs(e.Fragment,{children:[e.jsx("h2",{children:"Dungeon generation"}),e.jsxs("p",{children:["The dungeon generator was designed to create ",e.jsx("strong",{children:"unique, replayable level layouts"})," while maintaining a coherent structure and consistent gameplay flow, which would become crucial when implementing the genetic algorithm component of the DDA system. Each level consists of a series of combat rooms populated with enemies and cover, with a chance for adjacent side rooms to spawn containing loot chests."]}),e.jsx("p",{children:"Instead of long connecting corridors, the system uses paired teleporters to link rooms, allowing for instantaneous travel and simplifying navigation. These teleporters also serve as gating mechanisms, locking the player inside a combat room during encounters and unlocking it only once all enemies have been defeated, ensuring a controlled pacing of progression."}),e.jsx("p",{children:"The algorithm divides the generation process into distinct stages: room placement, connection linking, object population, and tilemap rendering. This structure allowed for efficient iteration and parameter tuning without affecting other components."}),e.jsx("a",{className:"link",href:"https://github.com/roryjns/mutagenesis/blob/main/Assets/Scripts/Dungeon%20Generator.cs",children:"View code"}),e.jsx("h2",{children:"Enemy AI"}),e.jsxs("p",{children:["Enemy behaviour is controlled by a ",e.jsx("strong",{children:"finite state machine"}),", illustrated in the diagram below. This approach made the logic straightforward to extend and debug, while ensuring enemies react appropriately to the player and the environment."]}),e.jsxs("p",{children:["Enemies within the same room are ",e.jsx("strong",{children:"grouped into clusters"})," that share the player’s last known position, allowing them to coordinate their movements and converge on the player’s position, rather than acting in isolation. Pathfinding is handled using Unity’s ",e.jsx("strong",{children:"NavMesh"})," system, enabling enemies to navigate efficiently around cover."]}),e.jsx("p",{children:"While the overall enemy AI was sufficient for the purposes of the project, it is relatively simple in practice. If I were to continue development I would look to expand the enemy AI with features such as coordinated flanking and cover selection to create more intelligent group dynamics."}),e.jsx("a",{className:"link",href:"https://github.com/roryjns/mutagenesis/blob/main/Assets/Scripts/Enemy.cs",children:"View code"}),e.jsx("h2",{children:"Adaptive loot system"}),e.jsxs("div",{children:[e.jsxs("p",{children:["Instead of fixed drop rates, the adaptive loot system calculates weighted probabilities for all lootable items whenever an enemy is defeated or a chest is opened. Some ",e.jsx("strong",{children:"baseline rules"})," are imposed beforehand to preserve game balance and player expectations:"]}),e.jsxs("ul",{children:[e.jsx("li",{children:"The chest in the starting room always spawns a weapon to prevent forced melee-only runs."}),e.jsx("li",{children:"Enemies can only drop weapons or ammo that match their type."}),e.jsx("li",{children:"Enemies never drop armour, since its already rewarded through finishers and this would make them less important."}),e.jsx("li",{children:"Health and armour will never drop while the player is full, preventing stockpiling."})]}),e.jsxs("p",{children:["Upon opening a chest or defeating an enemy, the drop weights for health, armour and ammo pickups are adjusted using a ",e.jsx("strong",{children:"linear interpolation function"})," that prioritises resources the player is low on:"]}),e.jsx(t,{math:"W = W_0 \\cdot [a+(b-a)(1-R)]"}),e.jsxs("p",{children:["Here, ",e.jsx(a,{math:"W"})," is the adjusted drop weight, ",e.jsx(a,{math:"W_0"})," is the base weight, and ",e.jsx(a,{math:"R"})," represents the player’s current resource ratio (between 0 and 1). The constants ",e.jsx(a,{math:"a"})," and ",e.jsx(a,{math:"b"})," define the scaling bounds. For example, health and armour can scale from 0 to 2. Weapon weights are adjusted separately to encourage variety: the current weapon type scales down to 0.5, while others scale up to 2.5."]})]}),e.jsxs("p",{children:["Once all weights are adjusted, a ",e.jsx("strong",{children:"weighted random selection"})," determines the actual drop, keeping loot unpredictable but fair. This approach preserves the excitement of traditional random drops while ensuring that players rarely feel starved of key resources or overloaded with redundant items."]}),e.jsx("a",{className:"link",href:"https://github.com/roryjns/mutagenesis/blob/main/Assets/Scripts/Loot%20System.cs",children:"View code"}),e.jsx("h2",{children:"Genetic algorithm"}),e.jsx("p",{children:"The genetic algorithm evolves a population of enemy configurations over successive levels, optimising for the overall fairness of combat encounters. Each level is treated as a new generation, with each enemy cluster (one in every combat room) acting as a candidate solution. A cluster’s ‘chromosome’ encodes key difficulty parameters: health, attack range, accuracy and damage. After each encounter, fairness is calculated by comparing the damage enemies dealt against how much they were expected to deal. The chromosome of the fairest cluster in the level is carried forward and mutated to define the next level's enemy parameters."}),e.jsx("p",{children:"During testing, it became clear that player behaviour strongly influenced fairness results; cautious players generally took less damage, while aggressive players took more, regardless of actual difficulty. To account for this, I introduced a player aggressiveness metric, measured by the proportion of attack time spent within close range of enemies. This value is used to scale the expected effectiveness accordingly, resulting in more consistent fairness readings across playstyles and a more reliable basis for evolving enemy difficulty."}),e.jsx("p",{children:"This problem highlights one of the key challenges of dynamic difficulty adjustment: accounting for the inherent variability in player behaviour, independent of skill level. Factoring in aggressiveness captures some of this complexity, but the algorithm could certainly be expanded to consider deeper context."}),e.jsxs("p",{children:["Gameplay data was collected remotely from playtesters through Unity Analytics using two anonymised builds of the game, one with DDA enabled and one without. The DDA version achieved both ",e.jsx("strong",{children:"higher peak fairness"})," and a ",e.jsx("strong",{children:"more consistent average fairness"})," across levels compared to the static difficulty build. Player feedback supported these results, with most participants either preferring the DDA version or perceiving no noticeable difference."]}),e.jsx("a",{className:"link",href:"https://github.com/roryjns/mutagenesis/blob/main/Assets/Scripts/Difficulty%20Manager.cs",children:"View code"})]}),whatIlearned:e.jsxs(e.Fragment,{children:[e.jsx("p",{children:"Developing Mutagenesis was an incredibly rewarding challenge that pushed every aspect of my design and programming ability. I improved my skills in structuring complex, interdependent systems in a way that remains modular, scalable, and maintainable. More importantly, it gave me hands-on experience in applying AI techniques to real-time gameplay, bridging theory and practical design."}),e.jsxs("p",{children:["This project also deepened my understanding of player psychology and game balance, showing how subtle factors like playstyle variability can complicate adaptive systems. Looking back, Mutagenesis represents ",e.jsx("strong",{children:"a milestone in my technical growth"}),", which I’m eager to build upon in future projects."]}),e.jsxs("p",{children:["My dissertation documenting the development of Mutagenesis achieved a first with a grade of 76%. You can find that "," ",e.jsx("a",{className:"link",href:"https://drive.google.com/file/d/10m_iVPWUA42SnmDAVktR1cepsgthXLM-/view?usp=sharing",children:"here"}),", and view the source code on my"," ",e.jsx("a",{className:"link",href:"https://github.com/roryjns/mutagenesis",children:"GitHub"}),". You can ",e.jsx("strong",{children:"play a web build"}),"  of the game on "," ",e.jsx("a",{className:"link",href:"https://rory-simpson.itch.io/mutagenesis",children:"itch.io"}),"."]})]})},rhyver:{title:"Rhyver",media:[{type:"video",src:"/portfolio/rhyver.webm"},{type:"image",src:"/portfolio/rhyver2.webp"},{type:"image",src:"/portfolio/rhyver3.webp"}],duration:"6 Months",engine:"Unity (C#)",introduction:e.jsx(e.Fragment,{children:e.jsx("p",{children:"Rhyver is inspired by games such as Guitar Hero, where the player has to press the correct keys in time with the music as notes scroll down the screen to the player controllers at the bottom. Depending on when the player presses the corresponding key, they achieve a ‘perfect’, ‘good’ or ‘okay’ hit, or they miss the note entirely. More accurate hits score more points, and building up a high combo of consecutive hits will apply a multiplier. There is also an audio visualiser on both sides of the lane, which is synchronised to the music."})}),body:({InlineMath:a,BlockMath:t})=>e.jsxs(e.Fragment,{children:[e.jsx("h2",{children:"Note spawning"}),e.jsx("p",{children:"Notes spawn and de-spawn during runtime to reduce the number of objects in the scene at any given time. For each note, the game calculates the beat on which to spawn it, such that it reaches the bottom of the screen on the beat it correponds to. I faced an issue where despite this calculation, the notes were arriving too late. Not only were they arriving late, but the degree of lateness was different each time I ran the game. After days of trying to debug this, I realised that the game spent some time loading the audio into the scene before it could play it, and I needed to account for this offset when spawning the notes."}),e.jsx("a",{className:"link",href:"https://github.com/roryjns/Rhyver/blob/main/Assets/Scripts/NoteSpawner.cs",children:"View code"}),e.jsx("h2",{children:"Online leaderboards"}),e.jsx("p",{children:"Each level on the level select screen has its own menu, showing the player’s personal best score, their highest combo and a button to view the online leaderboard for that level. The online leaderboards are stored on Microsoft Azure Playfab, and the data is retrieved via JSON requests in a custom PlayfabManager class. The player does not need to create an account, as Playfab can generate one automatically when the game is launched on a given device for the first time."}),e.jsx("a",{className:"link",href:"https://github.com/roryjns/Rhyver/blob/main/Assets/Scripts/PlayFabManager.cs",children:"View code"})]}),whatIlearned:e.jsxs(e.Fragment,{children:[e.jsx("p",{}),e.jsxs("p",{children:["You can play the game on "," ",e.jsx("a",{className:"link",href:"https://rory-simpson.itch.io/rhyver",children:"itch.io"}),". , or view the source code on my "," ",e.jsx("a",{className:"link",href:"https://github.com/roryjns/rhyver",children:"GitHub"}),"."]})]})},lowertones:{title:"Lowertones",media:[{type:"video",src:"/portfolio/lowertones.webm"},{type:"image",src:"/portfolio/lowertones2.webp"},{type:"image",src:"/portfolio/lowertones3.webp"}],duration:"10 Weeks",engine:"Angular (TypeScript)",introduction:e.jsx(e.Fragment,{children:e.jsx("p",{})}),body:({InlineMath:a,BlockMath:t})=>e.jsxs(e.Fragment,{children:[e.jsx("h2",{children:"Tech report"}),e.jsx("p",{}),e.jsx("h2",{children:"Full stack feature"}),e.jsx("p",{})]}),whatIlearned:e.jsx(e.Fragment,{children:e.jsx("p",{})})},rudawful:{title:"Rudawful",media:[{type:"video",src:"/portfolio/rudawful.webm"},{type:"image",src:"/portfolio/rudawful2.webp"},{type:"image",src:"/portfolio/rudawful3.webp"}],duration:"1 Week",engine:"Unity (C#)",introduction:e.jsx(e.Fragment,{children:e.jsx("p",{children:"Rudawful was made within a week for my second game jam, with the theme “running out of energy”. You play as Rudolph, dodging obstacles while munching on as many carrots as you can find to top up your energy bar. It was my second project to include online leaderboards, this time making players compete to finish the levels as fast as possible."})}),body:({InlineMath:a,BlockMath:t})=>e.jsx(e.Fragment,{}),whatIlearned:e.jsx(e.Fragment,{children:e.jsx("p",{children:"My focus for this project was to put my existing knowledge of Unity to practice in a much more fast-paced and efficient manner than I had done previously. Some features had to be scrapped (such as a tutorial level and a scrolling parallax background), but the end result felt more polished and complete than my previous game jam effort, which suffered from an over-ambitious scope of features that could not be fully realised in time for the deadline."})})},"brie-afraid":{title:"Brie Afraid",media:[{type:"video",src:"/portfolio/brie-afraid.webm"},{type:"image",src:"/portfolio/brie-afraid2.webp"},{type:"image",src:"/portfolio/brie-afraid3.webp"}],duration:"1 Week",engine:"Unity (C#)",introduction:e.jsx(e.Fragment,{children:e.jsx("p",{children:"This was made for my first game jam, with the theme “something else, and cheese”. You play as a mouse, lost in a maze with the mission of finding your friend, but with a sinister reversal of roles. Cheese-themed monsters roam the maze and will hunt you if you get too close. The player must collect all three keys scattered across the maze to unlock the door in the centre and free their friend..."})}),body:({InlineMath:a,BlockMath:t})=>e.jsxs(e.Fragment,{children:[e.jsx("h2",{children:"Enemy AI"}),e.jsx("p",{children:"The maze was created using a Unity tilemap. The enemies each patrol a section of the maze by simply moving to the next point in an array of points, and then moving backwards through the array. This made patrolling easier to implement and prevented the need for some alternative such as A* pathfinding. If I were to update the game, I would make the maze procedural to increase replayability (which would likely require an alternative patrolling system), improve the lighting system so the player can’t see through walls, and address balancing issues with the enemies appearing too suddenly and being difficult to escape from."})]}),whatIlearned:e.jsx(e.Fragment,{children:e.jsx("p",{})})}};function f(){const{projectId:a}=p(),t=g[a],[c,h]=s.useState(!1),[o,d]=s.useState(null),[l,m]=s.useState(null);return s.useEffect(()=>{let i=!0;return r(()=>import("./react-katex-447OEPN7.js").then(n=>n.r),__vite__mapDeps([5,2,3,4])).then(n=>{i&&(d(()=>n.InlineMath),m(()=>n.BlockMath),h(!0))}),()=>{i=!1}},[]),t?e.jsxs("div",{className:"project-page",children:[e.jsx("a",{className:"link",href:"/portfolio/",children:"< Back"}),e.jsx("div",{className:"project-title",children:t.title}),e.jsx("div",{className:"carousel-container",children:e.jsx(s.Suspense,{fallback:e.jsx("div",{className:"carousel-placeholder"}),children:e.jsx(u,{showIndicators:!0,showArrows:!0,showStatus:!1,showThumbs:!1,children:t.media.map((i,n)=>e.jsx("div",{className:"carousel-item",children:i.type==="video"?e.jsx("video",{autoPlay:!0,loop:!0,muted:!0,playsInline:!0,preload:"metadata",children:e.jsx("source",{src:i.src,type:"video/webm"})}):e.jsx("img",{src:i.src,alt:`${t.title} screenshot ${n+1}`,loading:"lazy"})},n))})})}),e.jsx("h2",{children:"Introduction"}),t.introduction,c&&o&&l?t.body({InlineMath:o,BlockMath:l}):e.jsx("p",{children:"Loading content..."}),e.jsx("h2",{children:"What I learned"}),t.whatIlearned]}):e.jsxs("div",{className:"page-not-found",children:[e.jsx("h1",{children:"PAGE NOT FOUND"}),e.jsx("a",{className:"link",href:"/portfolio/",children:"< Back"})]})}export{f as default};
